{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Test Notebook\n",
    "\n",
    "This notebook provides a function to test LLM API calls using log parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from collections import namedtuple\n",
    "from io import BytesIO\n",
    "\n",
    "import google.generativeai as genai\n",
    "from anthropic import Anthropic\n",
    "from google.generativeai import caching\n",
    "from openai import OpenAI\n",
    "from balrog.client import OpenAIWrapper, LLMResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test_api_call function\n",
    "def test_api_call(log_data):\n",
    "    \"\"\"Test function to manually call the API using log parameters.\n",
    "    \n",
    "    Args:\n",
    "        log_data (dict): Dictionary containing the API call parameters from logs.\n",
    "            Expected format:\n",
    "            {\n",
    "                \"messages\": list of message dicts,\n",
    "                \"model\": str,\n",
    "                \"temperature\": float\n",
    "            }\n",
    "    \n",
    "    Returns:\n",
    "        LLMResponse: The response from the API.\n",
    "    \"\"\"\n",
    "    # Create a mock client config\n",
    "    class MockClientConfig:\n",
    "        def __init__(self, model_id, temperature):\n",
    "            self.client_name = \"openai\"  # Default to OpenAI\n",
    "            self.model_id = model_id\n",
    "            self.base_url = None\n",
    "            self.timeout = 30\n",
    "            self.generate_kwargs = {\"temperature\": temperature}\n",
    "            self.max_retries = 3\n",
    "            self.delay = 1\n",
    "            self.alternate_roles = False\n",
    "\n",
    "    # Create client config from log data\n",
    "    client_config = MockClientConfig(\n",
    "        model_id=log_data[\"model\"],\n",
    "        temperature=log_data.get(\"temperature\", 1.0)\n",
    "    )\n",
    "    \n",
    "    # Create the appropriate client\n",
    "    client = OpenAIWrapper(client_config)\n",
    "    \n",
    "    # Convert messages to the format expected by the client\n",
    "    class Message:\n",
    "        def __init__(self, role, content, attachment=None):\n",
    "            self.role = role\n",
    "            self.content = content\n",
    "            self.attachment = attachment\n",
    "    \n",
    "    messages = [\n",
    "        Message(msg[\"role\"], msg[\"content\"])\n",
    "        for msg in log_data[\"messages\"]\n",
    "    ]\n",
    "    \n",
    "    # Make the API call\n",
    "    try:\n",
    "        response = client.generate(messages)\n",
    "        print(f\"API Call Successful!\")\n",
    "        print(f\"Model: {response.model_id}\")\n",
    "        print(f\"Completion: {response.completion}\")\n",
    "        print(f\"Stop Reason: {response.stop_reason}\")\n",
    "        print(f\"Input Tokens: {response.input_tokens}\")\n",
    "        print(f\"Output Tokens: {response.output_tokens}\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"API Call Failed: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Here's how to use the test_api_call function with your log data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Call Failed: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m\n\u001b[1;32m      2\u001b[0m log_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      4\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Make the API call\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mtest_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 52\u001b[0m, in \u001b[0;36mtest_api_call\u001b[0;34m(log_data)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Make the API call\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI Call Successful!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/f/MachineLearning/Sundai_Club/LLM_Gaming/balrog/BALROG/balrog/client.py:221\u001b[0m, in \u001b[0;36mOpenAIWrapper.generate\u001b[0;34m(self, messages)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, messages):\n\u001b[1;32m    213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate a response from the OpenAI API given a list of messages.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m        LLMResponse: The response from the OpenAI API.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     converted_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_messages(messages)\n\u001b[1;32m    223\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking API call to model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/f/MachineLearning/Sundai_Club/LLM_Gaming/balrog/BALROG/balrog/client.py:174\u001b[0m, in \u001b[0;36mOpenAIWrapper._initialize_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI API Key present: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mapi_key\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    173\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI Key length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(api_key)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mapi_key\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/balrog/lib/python3.10/site-packages/openai/_client.py:116\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    114\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Example log data\n",
    "log_data = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"You are an agent playing TextWorld, a text-based adventure game where you are in a randomly generated\\n    maze and must find the coin. You need to explore different rooms to find the target object.\\n    Here are the available commands: goal: print the goal of this game go <dir>: move the player north, east,\\n    south, or west. You can only go in the direction indicated with something like an exit or a door. take coin:\\n    2in the game by 'take coin' if you see the coin in the room\\n    The only action you can do is go <dir> to explore the maze and 'take coin' when you see the coin in the\\n    room.\\n    You have 80 steps to complete the task. Restarting is forbidden.Observation:\\n-= Bathroom =-\\nYou've entered a bathroom. I guess you better just go and list everything you see here.\\n\\n\\n\\nYou need an unguarded exit? You should try going east. There is an exit to the north. Don't worry, it is unguarded. There is an exit to the west. Don't worry, it is unguarded.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Previous plan:\\n```\\n<scratch-pad>\\nMAP:\\n- Bathroom: exits N? E? W?, visited=True\\nPATH: [Bathroom]\\nFirst unexplored exit in Bathroom: N\\n</scratch-pad>\\n<|ACTION|>go north<|END|>\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Observation:\\n-= Salon =-\\nYou've seen better salons, but at least this one seems pretty typical. You begin to take stock of what's in the room.\\n\\n\\n\\nThere is an unblocked exit to the east. There is an exit to the north. Don't worry, it is unblocked. There is an unguarded exit to the south. You don't like doors? Why not try going west, that entranceway is unguarded.\"\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"deepseek-reasoner\",\n",
    "    \"temperature\": 1\n",
    "}\n",
    "\n",
    "# Make the API call\n",
    "response = test_api_call(log_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Notes\n",
    "\n",
    "1. Make sure you have the necessary API keys set up in your environment variables:\n",
    "   - For OpenAI models: Set `OPENAI_API_KEY`\n",
    "   - For Claude models: Set `ANTHROPIC_API_KEY`\n",
    "   - For Gemini models: Set `GOOGLE_API_KEY`\n",
    "\n",
    "2. The notebook includes retry logic (3 retries with exponential backoff) in case of temporary failures\n",
    "\n",
    "3. You can modify the log_data dictionary to test different scenarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "balrog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
